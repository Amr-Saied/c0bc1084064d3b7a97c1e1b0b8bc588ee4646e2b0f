{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "U-Net"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ayamohamdd/IP-25.git\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:27:09.679604Z",
          "iopub.execute_input": "2024-12-16T03:27:09.680352Z",
          "iopub.status.idle": "2024-12-16T03:27:23.082344Z",
          "shell.execute_reply.started": "2024-12-16T03:27:09.680316Z",
          "shell.execute_reply": "2024-12-16T03:27:23.081276Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egZcq5MLhdtf",
        "outputId": "5e478cb3-702d-4565-b4b5-b957c1c1215e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'IP-25'...\nremote: Enumerating objects: 709, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 709 (delta 0), reused 3 (delta 0), pack-reused 700 (from 1)\u001b[K\nReceiving objects: 100% (709/709), 403.03 MiB | 50.06 MiB/s, done.\nUpdating files: 100% (691/691), done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image, ImageEnhance\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:13.38399Z",
          "iopub.execute_input": "2024-12-16T03:29:13.384805Z",
          "iopub.status.idle": "2024-12-16T03:29:25.222047Z",
          "shell.execute_reply.started": "2024-12-16T03:29:13.384766Z",
          "shell.execute_reply": "2024-12-16T03:29:25.221337Z"
        },
        "id": "bDMi2BFHhdtk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Paths to the directories\n",
        "# train_image_paths = r\"/content/IP-25/train_data/Images\"\n",
        "# train_mask_paths = r\"/content/IP-25/train_data/Labels\"\n",
        "\n",
        "# # Output paths\n",
        "# output_image_path = train_image_paths\n",
        "# output_mask_path = train_mask_paths\n",
        "\n",
        "# # Image augmentation setup\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=40,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "\n",
        "# # Get lists of image and mask files\n",
        "# image_files = sorted([file for file in os.listdir(train_image_paths) if file.lower().endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif', 'tiff'))])\n",
        "# mask_files = sorted([file for file in os.listdir(train_mask_paths) if file.lower().endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif', 'tiff'))])\n",
        "\n",
        "# # Ensure that image and mask filenames correspond (e.g., \"image1.jpg\" matches \"mask1.jpg\")\n",
        "# assert len(image_files) == len(mask_files), \"Mismatch in the number of images and masks!\"\n",
        "# for img_file, mask_file in zip(image_files, mask_files):\n",
        "#     assert os.path.splitext(img_file)[0] == os.path.splitext(mask_file)[0], \"Image and mask filenames do not match!\"\n",
        "\n",
        "# # Augment each image-mask pair\n",
        "# counter = 0\n",
        "# for img_file, mask_file in zip(image_files, mask_files):\n",
        "#     # Load the image and mask\n",
        "#     img_path = os.path.join(train_image_paths, img_file)\n",
        "#     mask_path = os.path.join(train_mask_paths, mask_file)\n",
        "#     img = img_to_array(load_img(img_path))\n",
        "#     mask = img_to_array(load_img(mask_path, color_mode=\"rgb\"))  # Ensure mask is grayscale\n",
        "\n",
        "#     # Expand dimensions to match the generator input format\n",
        "#     img = np.expand_dims(img, axis=0)\n",
        "#     mask = np.expand_dims(mask, axis=0)\n",
        "\n",
        "#     # Create a combined generator for both image and mask\n",
        "#     seed = np.random.randint(0, 10000)  # Use the same seed for both\n",
        "#     aug_img_iter = datagen.flow(img, batch_size=1, seed=seed)\n",
        "#     aug_mask_iter = datagen.flow(mask, batch_size=1, seed=seed)\n",
        "\n",
        "#     # Generate augmented images and masks\n",
        "#     for i in range(3):  # Create 3 augmentations per image-mask pair\n",
        "#         aug_img = next(aug_img_iter)[0].astype('uint8')  # Augmented image\n",
        "#         aug_mask = next(aug_mask_iter)[0].astype('uint8')  # Augmented mask\n",
        "\n",
        "#         # Save augmented image and mask with unique names\n",
        "#         img_name = f\"aug_{counter}_{img_file}\"\n",
        "#         mask_name = f\"aug_{counter}_{mask_file}\"\n",
        "#         save_img(os.path.join(output_image_path, img_name), aug_img)\n",
        "#         save_img(os.path.join(output_mask_path, mask_name), aug_mask)\n",
        "#         counter += 1\n",
        "\n",
        "# print(f\"Data augmentation complete! Total augmented pairs: {counter}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgbvGZhXzkC4",
        "outputId": "41029e7d-d03e-45fd-ad40-136593d732ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation complete! Total augmented pairs: 600\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(image_paths, target_size=(256, 256)):\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        # Load image\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "        img = img_to_array(img) / 255.0  # Normalize images to [0, 1]\n",
        "\n",
        "        # Convert to uint8 for OpenCV processing\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "\n",
        "        # Decrease brightness\n",
        "        img = cv2.convertScaleAbs(img, alpha=0.8, beta=0)  # Reduce brightness by 20%\n",
        "\n",
        "        # Apply Gaussian blur\n",
        "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "        # Normalize back to [0, 1] after processing\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "\n",
        "\n",
        "# Map RGB values to class indices\n",
        "def rgb_to_class_index(mask_rgb):\n",
        "    color_map = {\n",
        "        (0, 0, 0): 0,         # Background clutter\n",
        "        (128, 0, 0): 1,       # Building\n",
        "        (128, 64, 128): 2,    # Road\n",
        "        (0, 128, 0): 3,       # Tree\n",
        "        (128, 128, 0): 4,     # Low vegetation\n",
        "        (64, 0, 128): 5,      # Moving car\n",
        "        (192, 0, 192): 6,     # Static car\n",
        "        (64, 64, 0): 7        # Human\n",
        "    }\n",
        "\n",
        "    # Find the closest color in the map to the input RGB value\n",
        "    min_distance = float('inf')\n",
        "    closest_color = None\n",
        "    for color, index in color_map.items():\n",
        "        distance = np.linalg.norm(np.array(mask_rgb) - np.array(color))  # Euclidean distance\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            closest_color = index\n",
        "\n",
        "    return closest_color\n",
        "\n",
        "def load_masks(mask_paths, target_size=(256, 256)):\n",
        "    masks = []\n",
        "    for mask_path in mask_paths:\n",
        "        mask = load_img(mask_path, target_size=target_size)\n",
        "        mask = img_to_array(mask)\n",
        "        # Convert RGB values to class indices (0 to 7)\n",
        "        mask_class_indices = np.apply_along_axis(rgb_to_class_index, 2, mask.astype(int))\n",
        "        masks.append(mask_class_indices)\n",
        "    return np.array(masks)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:34.05186Z",
          "iopub.execute_input": "2024-12-16T03:29:34.052837Z",
          "iopub.status.idle": "2024-12-16T03:29:34.062898Z",
          "shell.execute_reply.started": "2024-12-16T03:29:34.052802Z",
          "shell.execute_reply": "2024-12-16T03:29:34.062065Z"
        },
        "id": "uSaVwpcPhdtm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
        "\n",
        "def unet_model(input_size=(256, 256, 3), num_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Contracting path (Encoder)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Expansive path (Decoder)\n",
        "    up5 = UpSampling2D((2, 2))(conv4)\n",
        "    concat5 = Concatenate()([up5, conv3])\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat5)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = UpSampling2D((2, 2))(conv5)\n",
        "    concat6 = Concatenate()([up6, conv2])\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = UpSampling2D((2, 2))(conv6)\n",
        "    concat7 = Concatenate()([up7, conv1])\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Final layer (output)\n",
        "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "    return model\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:41.90989Z",
          "iopub.execute_input": "2024-12-16T03:29:41.910527Z",
          "iopub.status.idle": "2024-12-16T03:29:41.921427Z",
          "shell.execute_reply.started": "2024-12-16T03:29:41.910495Z",
          "shell.execute_reply": "2024-12-16T03:29:41.920818Z"
        },
        "id": "or5I1mdFhdto"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Rand Index - compares predicted and true labels\n",
        "def rand_index(y_true, y_pred):\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=-1)  # Convert probabilities to class indices\n",
        "    y_true_flat = tf.keras.backend.flatten(y_true)  # Flatten ground truth\n",
        "    y_pred_flat = tf.keras.backend.flatten(y_pred_classes)  # Flatten predictions\n",
        "    equal = tf.reduce_sum(tf.cast(tf.equal(y_true_flat, y_pred_flat), tf.float32))  # Count equal pairs\n",
        "    total_pairs = tf.cast(tf.size(y_true_flat, out_type=tf.int32), tf.float32)  # Get total number of elements\n",
        "    return equal / (total_pairs + tf.keras.backend.epsilon())  # Avoid divide by zero\n",
        "\n",
        "\n",
        "# Jaccard Index (IoU) - Adjusted for probabilities\n",
        "def jaccard_index(y_true, y_pred):\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
        "    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
        "    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n",
        "    intersection = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n",
        "    union = tf.reduce_sum(y_true_one_hot + y_pred_one_hot, axis=[1, 2]) - intersection\n",
        "    return tf.reduce_mean(intersection / (union + tf.keras.backend.epsilon()))\n",
        "\n",
        "# Precision\n",
        "def precision(y_true, y_pred):\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
        "    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
        "    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n",
        "    true_positives = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n",
        "    predicted_positives = tf.reduce_sum(y_pred_one_hot, axis=[1, 2])\n",
        "    return tf.reduce_mean(true_positives / (predicted_positives + tf.keras.backend.epsilon()))\n",
        "\n",
        "# Recall\n",
        "def recall(y_true, y_pred):\n",
        "    y_pred_classes = tf.argmax(y_pred, axis=-1)\n",
        "    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
        "    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n",
        "    true_positives = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n",
        "    actual_positives = tf.reduce_sum(y_true_one_hot, axis=[1, 2])\n",
        "    return tf.reduce_mean(true_positives / (actual_positives + tf.keras.backend.epsilon()))\n",
        "\n",
        "\n",
        "\n",
        "model = unet_model(input_size=(256, 256, 3), num_classes=8)\n",
        "# Compile with updated metrics\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy', rand_index, jaccard_index, precision, recall]\n",
        ")\n",
        "\n",
        "model2 = unet_model(input_size=(256, 256, 3), num_classes=8)\n",
        "# Compile with updated metrics\n",
        "model2.compile(\n",
        "    optimizer=SGD(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy', rand_index, jaccard_index, precision, recall]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:46.970863Z",
          "iopub.execute_input": "2024-12-16T03:29:46.971214Z",
          "iopub.status.idle": "2024-12-16T03:29:47.963465Z",
          "shell.execute_reply.started": "2024-12-16T03:29:46.971186Z",
          "shell.execute_reply": "2024-12-16T03:29:47.962699Z"
        },
        "id": "zirEXnU3hdtp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_paths(directory, extensions=[\".jpg\", \".png\"]):\n",
        "    return [os.path.join(directory, filename) for filename in os.listdir(directory) if any(filename.endswith(ext) for ext in extensions)]\n",
        "\n",
        "# Get file paths for images and masks\n",
        "train_image_paths = get_image_paths(r\"/kaggle/working/IP-25/train_data/Images\")\n",
        "train_mask_paths = get_image_paths(r\"/kaggle/working/IP-25/train_data/Labels\")\n",
        "val_image_paths = get_image_paths(r\"/kaggle/working/IP-25/val_data/Images\")\n",
        "val_mask_paths = get_image_paths(r\"/kaggle/working/IP-25/val_data/Labels\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:53.250786Z",
          "iopub.execute_input": "2024-12-16T03:29:53.251522Z",
          "iopub.status.idle": "2024-12-16T03:29:53.258988Z",
          "shell.execute_reply.started": "2024-12-16T03:29:53.25149Z",
          "shell.execute_reply": "2024-12-16T03:29:53.258171Z"
        },
        "id": "q19xCasnhdtp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = load_images(train_image_paths)\n",
        "train_masks = load_masks(train_mask_paths)\n",
        "val_images = load_images(val_image_paths)\n",
        "val_masks = load_masks(val_mask_paths)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:29:55.590156Z",
          "iopub.execute_input": "2024-12-16T03:29:55.590602Z",
          "iopub.status.idle": "2024-12-16T03:40:49.898603Z",
          "shell.execute_reply.started": "2024-12-16T03:29:55.590554Z",
          "shell.execute_reply": "2024-12-16T03:40:49.897568Z"
        },
        "id": "sjuS8u7lhdtq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    train_masks,\n",
        "    validation_data=(val_images, val_masks),\n",
        "    epochs=120,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "history2 = model2.fit(\n",
        "    train_images,\n",
        "    train_masks,\n",
        "    validation_data=(val_images, val_masks),\n",
        "    epochs=120,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T03:45:47.846947Z",
          "iopub.execute_input": "2024-12-16T03:45:47.847735Z",
          "iopub.status.idle": "2024-12-16T04:03:19.748081Z",
          "shell.execute_reply.started": "2024-12-16T03:45:47.847702Z",
          "shell.execute_reply": "2024-12-16T04:03:19.747115Z"
        },
        "id": "K2PEevDfhdtr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_directory(directory_path, target_size=(256, 256), brightness_factor=0.5, blur_kernel_size=(5, 5)):\n",
        "    image_paths = [os.path.join(directory_path, fname) for fname in os.listdir(directory_path) if fname.endswith('.png')]  # Assuming images are PNG files\n",
        "    images = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        # Load the image and resize it\n",
        "        img = load_img(img_path, target_size=target_size)\n",
        "\n",
        "        # Convert to array and normalize\n",
        "        img = img_to_array(img) / 255.0\n",
        "\n",
        "        # Adjust brightness (lower the brightness by the given factor)\n",
        "        pil_img = Image.fromarray((img * 255).astype(np.uint8))  # Convert back to PIL for brightness enhancement\n",
        "        enhancer = ImageEnhance.Brightness(pil_img)\n",
        "        pil_img = enhancer.enhance(brightness_factor)\n",
        "\n",
        "        # Convert back to array\n",
        "        img = np.array(pil_img) / 255.0\n",
        "\n",
        "        # Apply Gaussian blur using OpenCV\n",
        "        img = cv2.GaussianBlur(img, blur_kernel_size, 0)\n",
        "\n",
        "        # Append the processed image\n",
        "        images.append(img)\n",
        "\n",
        "    return np.array(images), image_paths  # Return both images and their paths\n",
        "# Load images with preprocessing\n",
        "# def load_images_from_directory(directory_path, target_size=(256, 256)):\n",
        "#     images = []\n",
        "#     for img_path in image_paths:\n",
        "#         # Load image\n",
        "#         img = load_img(img_path, target_size=target_size)\n",
        "#         img = img_to_array(img) / 255.0  # Normalize images to [0, 1]\n",
        "\n",
        "#         # Convert to uint8 for OpenCV processing\n",
        "#         img = (img * 255).astype(np.uint8)\n",
        "\n",
        "#         # Decrease brightness\n",
        "#         img = cv2.convertScaleAbs(img, alpha=0.8, beta=0)  # Reduce brightness by 20%\n",
        "\n",
        "#         # Apply Gaussian blur\n",
        "#         img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "#         # Normalize back to [0, 1] after processing\n",
        "#         img = img.astype(np.float32) / 255.0\n",
        "\n",
        "#         images.append(img)\n",
        "#     return np.array(images)\n",
        "\n",
        "\n",
        "\n",
        "def visualize_prediction(image, predicted_mask):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Input Image')\n",
        "    plt.imshow(image)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.imshow(predicted_mask)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Directory paths for test images\n",
        "test_images_dir = r\"/kaggle/working/IP-25/test_data/Images\"\n",
        "# Optionally, if masks are needed later, you can add the path for ground truth masks\n",
        "# test_masks_dir = r\"/kaggle/working/IP-25/test_data/Masks/\"\n",
        "\n",
        "# Load test images\n",
        "test_images, image_paths = load_images_from_directory(test_images_dir)\n",
        "\n",
        "# Predict masks for the test images\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Visualize the predictions\n",
        "for i in range(len(test_images)):\n",
        "    # For visualization, only predicted masks are needed\n",
        "    predicted_mask = np.argmax(predictions[i], axis=-1)  # Convert to class labels if needed\n",
        "\n",
        "    # Visualize the input image and the predicted mask\n",
        "    visualize_prediction(test_images[i], predicted_mask)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-13T21:50:50.132436Z",
          "iopub.status.idle": "2024-12-13T21:50:50.132737Z",
          "shell.execute_reply.started": "2024-12-13T21:50:50.132593Z",
          "shell.execute_reply": "2024-12-13T21:50:50.132609Z"
        },
        "id": "WHSgHFfrhdts"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_mask(mask):\n",
        "    color_map = {\n",
        "        0: [0, 0, 0],  # Background clutter\n",
        "        1: [128, 0, 0],  # Building\n",
        "        2: [128, 64, 128],  # Road\n",
        "        3: [0, 128, 0],  # Tree\n",
        "        4: [128, 128, 0],  # Low vegetation\n",
        "        5: [64, 0, 128],  # Moving car\n",
        "        6: [192, 0, 192],  # Static car\n",
        "        7: [64, 64, 0]  # Human\n",
        "    }\n",
        "    rgb_mask = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
        "    for i in range(mask.shape[0]):\n",
        "        for j in range(mask.shape[1]):\n",
        "            rgb_mask[i, j] = color_map[mask[i, j]]\n",
        "    return rgb_mask\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-12T20:50:03.152354Z",
          "iopub.execute_input": "2024-12-12T20:50:03.152735Z",
          "iopub.status.idle": "2024-12-12T20:50:03.159201Z",
          "shell.execute_reply.started": "2024-12-12T20:50:03.152682Z",
          "shell.execute_reply": "2024-12-12T20:50:03.1581Z"
        },
        "id": "e04lDs1Hhdtt"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}