{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ayamohamdd/IP-25.git\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:33:02.277228Z","iopub.execute_input":"2024-12-16T00:33:02.277625Z","iopub.status.idle":"2024-12-16T00:33:15.526099Z","shell.execute_reply.started":"2024-12-16T00:33:02.277577Z","shell.execute_reply":"2024-12-16T00:33:15.525281Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'IP-25'...\nremote: Enumerating objects: 709, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 709 (delta 0), reused 3 (delta 0), pack-reused 700 (from 1)\u001b[K\nReceiving objects: 100% (709/709), 403.03 MiB | 49.45 MiB/s, done.\nUpdating files: 100% (691/691), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, UpSampling2D, Softmax,Dropout\nfrom tensorflow.keras.optimizers import Adam , SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\nimport numpy as np\nfrom PIL import Image, ImageEnhance\nimport matplotlib.pyplot as plt\nimport os\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:33:18.600342Z","iopub.execute_input":"2024-12-16T00:33:18.600970Z","iopub.status.idle":"2024-12-16T00:33:30.441951Z","shell.execute_reply.started":"2024-12-16T00:33:18.600932Z","shell.execute_reply":"2024-12-16T00:33:30.441235Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Paths to the directories\ntrain_image_paths = r\"/kaggle/working/IP-25/train_data/Images\"\ntrain_mask_paths = r\"/kaggle/working/IP-25/train_data/Labels\"\n\n# Output paths\noutput_image_path = train_image_paths\noutput_mask_path = train_mask_paths\n\n# Image augmentation setup\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Get lists of image and mask files\nimage_files = sorted([file for file in os.listdir(train_image_paths) if file.lower().endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif', 'tiff'))])\nmask_files = sorted([file for file in os.listdir(train_mask_paths) if file.lower().endswith(('jpg', 'jpeg', 'png', 'bmp', 'gif', 'tiff'))])\n\n# Ensure that image and mask filenames correspond (e.g., \"image1.jpg\" matches \"mask1.jpg\")\nassert len(image_files) == len(mask_files), \"Mismatch in the number of images and masks!\"\nfor img_file, mask_file in zip(image_files, mask_files):\n    assert os.path.splitext(img_file)[0] == os.path.splitext(mask_file)[0], \"Image and mask filenames do not match!\"\n\n# Augment each image-mask pair\ncounter = 0\nfor img_file, mask_file in zip(image_files, mask_files):\n    # Load the image and mask\n    img_path = os.path.join(train_image_paths, img_file)\n    mask_path = os.path.join(train_mask_paths, mask_file)\n    img = img_to_array(load_img(img_path))\n    mask = img_to_array(load_img(mask_path, color_mode=\"rgb\"))  # Ensure mask is grayscale\n\n    # Expand dimensions to match the generator input format\n    img = np.expand_dims(img, axis=0)\n    mask = np.expand_dims(mask, axis=0)\n\n    # Create a combined generator for both image and mask\n    seed = np.random.randint(0, 10000)  # Use the same seed for both\n    aug_img_iter = datagen.flow(img, batch_size=1, seed=seed)\n    aug_mask_iter = datagen.flow(mask, batch_size=1, seed=seed)\n\n    # Generate augmented images and masks\n    for i in range(3):  # Create 3 augmentations per image-mask pair\n        aug_img = next(aug_img_iter)[0].astype('uint8')  # Augmented image\n        aug_mask = next(aug_mask_iter)[0].astype('uint8')  # Augmented mask\n\n        # Save augmented image and mask with unique names\n        img_name = f\"aug_{counter}_{img_file}\"\n        mask_name = f\"aug_{counter}_{mask_file}\"\n        save_img(os.path.join(output_image_path, img_name), aug_img)\n        save_img(os.path.join(output_mask_path, mask_name), aug_mask)\n        counter += 1\n\nprint(f\"Data augmentation complete! Total augmented pairs: {counter}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:33:35.027520Z","iopub.execute_input":"2024-12-16T00:33:35.028383Z","iopub.status.idle":"2024-12-16T00:37:51.317934Z","shell.execute_reply.started":"2024-12-16T00:33:35.028345Z","shell.execute_reply":"2024-12-16T00:37:51.316902Z"}},"outputs":[{"name":"stdout","text":"Data augmentation complete! Total augmented pairs: 600\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# import os\n# import matplotlib.pyplot as plt\n# from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# # Paths to the directories with augmented images and masks\n# augmented_image_path = r\"/kaggle/working/IP-25/train_data/Images\"\n# augmented_mask_path = r\"/kaggle/working/IP-25/train_data/Labels\"\n\n# # Get lists of augmented image and mask files\n# augmented_image_files = sorted([file for file in os.listdir(augmented_image_path) if file.startswith(\"aug_\")])\n# augmented_mask_files = sorted([file for file in os.listdir(augmented_mask_path) if file.startswith(\"aug_\")])\n\n# # Ensure that image and mask filenames correspond\n# assert len(augmented_image_files) == len(augmented_mask_files), \"Mismatch in the number of augmented images and masks!\"\n# for img_file, mask_file in zip(augmented_image_files, augmented_mask_files):\n#     assert os.path.splitext(img_file)[0] == os.path.splitext(mask_file)[0], \"Augmented image and mask filenames do not match!\"\n\n# # Display the augmented images and their corresponding masks\n# for img_file, mask_file in zip(augmented_image_files, augmented_mask_files):\n#     # Load the augmented image and mask\n#     img_path = os.path.join(augmented_image_path, img_file)\n#     mask_path = os.path.join(augmented_mask_path, mask_file)\n#     img = img_to_array(load_img(img_path))  # Load augmented image\n#     mask = img_to_array(load_img(mask_path, color_mode=\"rgb\")).squeeze()  # Load augmented mask\n\n#     # Plot the image and corresponding mask\n#     plt.figure(figsize=(8, 4))\n#     plt.subplot(1, 2, 1)\n#     plt.imshow(img.astype('uint8'))\n#     plt.title(f\"Augmented Image: {img_file}\")\n#     plt.axis(\"off\")\n    \n#     plt.subplot(1, 2, 2)\n#     plt.imshow(mask)\n#     plt.title(f\"Augmented Mask: {mask_file}\")\n#     plt.axis(\"off\")\n    \n#     plt.show()  # Show the plots","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:27:55.639185Z","iopub.execute_input":"2024-12-16T00:27:55.639791Z","iopub.status.idle":"2024-12-16T00:27:55.644410Z","shell.execute_reply.started":"2024-12-16T00:27:55.639761Z","shell.execute_reply":"2024-12-16T00:27:55.643635Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_images(image_paths, target_size=(256, 256)):\n    images = []\n    for img_path in image_paths:\n        # Load image\n        img = load_img(img_path, target_size=target_size)\n        img = img_to_array(img) / 255.0  # Normalize images to [0, 1]\n\n        # Convert to uint8 for OpenCV processing\n        img = (img * 255).astype(np.uint8)\n\n        # Decrease brightness\n        img = cv2.convertScaleAbs(img, alpha=0.8, beta=0)  # Reduce brightness by 20%\n\n        # Apply Gaussian blur\n        img = cv2.GaussianBlur(img, (5, 5), 0)\n\n        # Normalize back to [0, 1] after processing\n        img = img.astype(np.float32) / 255.0\n\n        images.append(img)\n    return np.array(images)\n\ndef rgb_to_class_index(mask_rgb):\n    color_map = {\n        (0, 0, 0): 0,         # Background clutter\n        (128, 0, 0): 1,       # Building\n        (128, 64, 128): 2,    # Road\n        (0, 128, 0): 3,       # Tree\n        (128, 128, 0): 4,     # Low vegetation\n        (64, 0, 128): 5,      # Moving car\n        (192, 0, 192): 6,     # Static car\n        (64, 64, 0): 7        # Human\n    }\n\n    min_distance = float('inf')\n    closest_color = None\n    for color, index in color_map.items():\n        distance = np.linalg.norm(np.array(mask_rgb) - np.array(color))  # Euclidean distance\n        if distance < min_distance:\n            min_distance = distance\n            closest_color = index\n\n    return closest_color","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:38:00.193546Z","iopub.execute_input":"2024-12-16T00:38:00.194530Z","iopub.status.idle":"2024-12-16T00:38:00.202578Z","shell.execute_reply.started":"2024-12-16T00:38:00.194494Z","shell.execute_reply":"2024-12-16T00:38:00.201526Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_masks(mask_paths, target_size=(256, 256)):\n    masks = []\n    for mask_path in mask_paths:\n        mask = load_img(mask_path, target_size=target_size)\n        mask = img_to_array(mask)\n        mask_class_indices = np.apply_along_axis(rgb_to_class_index, 2, mask.astype(int))\n        masks.append(mask_class_indices)\n    return np.array(masks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T00:38:04.175189Z","iopub.execute_input":"2024-12-16T00:38:04.175538Z","iopub.status.idle":"2024-12-16T00:38:04.180681Z","shell.execute_reply.started":"2024-12-16T00:38:04.175506Z","shell.execute_reply":"2024-12-16T00:38:04.179736Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def segnet_model(input_size=(256, 256, 3), num_classes=8, dropout_rate=0.5):\n    inputs = Input(input_size)\n\n    # Encoder\n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    # Decoder\n    up3 = UpSampling2D(size=(2, 2))(pool3)\n    conv4 = Conv2D(256, (3, 3), padding='same')(up3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    conv4 = Conv2D(256, (3, 3), padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    conv4 = Conv2D(128, (3, 3), padding='same')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n\n    up2 = UpSampling2D(size=(2, 2))(conv4)\n    conv5 = Conv2D(128, (3, 3), padding='same')(up2)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv5 = Conv2D(64, (3, 3), padding='same')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n\n    up1 = UpSampling2D(size=(2, 2))(conv5)\n    conv6 = Conv2D(64, (3, 3), padding='same')(up1)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    conv6 = Conv2D(64, (3, 3), padding='same')(conv6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n\n    # Dropout layer\n    conv6 = Dropout(dropout_rate)(conv6)\n\n    # Output layer\n    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv6)\n\n    model = Model(inputs, output)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:49:30.039256Z","iopub.execute_input":"2024-12-16T01:49:30.039634Z","iopub.status.idle":"2024-12-16T01:49:30.052115Z","shell.execute_reply.started":"2024-12-16T01:49:30.039605Z","shell.execute_reply":"2024-12-16T01:49:30.051067Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def rand_index(y_true, y_pred):\n    y_pred_classes = tf.argmax(y_pred, axis=-1)  # Convert probabilities to class indices\n    y_true_flat = tf.keras.backend.flatten(y_true)  # Flatten ground truth\n    y_pred_flat = tf.keras.backend.flatten(y_pred_classes)  # Flatten predictions\n    equal = tf.reduce_sum(tf.cast(tf.equal(y_true_flat, y_pred_flat), tf.float32))  # Count equal pairs\n    total_pairs = tf.cast(tf.size(y_true_flat, out_type=tf.int32), tf.float32)  # Get total number of elements\n    return equal / (total_pairs + tf.keras.backend.epsilon())  # Avoid divide by zero\n\n\n# Jaccard Index (IoU) - Adjusted for probabilities\ndef jaccard_index(y_true, y_pred):\n    y_pred_classes = tf.argmax(y_pred, axis=-1)\n    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n    intersection = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n    union = tf.reduce_sum(y_true_one_hot + y_pred_one_hot, axis=[1, 2]) - intersection\n    return tf.reduce_mean(intersection / (union + tf.keras.backend.epsilon()))\n\n# Precision\ndef precision(y_true, y_pred):\n    y_pred_classes = tf.argmax(y_pred, axis=-1)\n    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n    true_positives = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n    predicted_positives = tf.reduce_sum(y_pred_one_hot, axis=[1, 2])\n    return tf.reduce_mean(true_positives / (predicted_positives + tf.keras.backend.epsilon()))\n\n# Recall\ndef recall(y_true, y_pred):\n    y_pred_classes = tf.argmax(y_pred, axis=-1)\n    y_true_one_hot = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n    y_pred_one_hot = tf.one_hot(y_pred_classes, depth=tf.shape(y_pred)[-1])\n    true_positives = tf.reduce_sum(y_true_one_hot * y_pred_one_hot, axis=[1, 2])\n    actual_positives = tf.reduce_sum(y_true_one_hot, axis=[1, 2])\n    return tf.reduce_mean(true_positives / (actual_positives + tf.keras.backend.epsilon()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:49:33.074200Z","iopub.execute_input":"2024-12-16T01:49:33.074777Z","iopub.status.idle":"2024-12-16T01:49:33.084408Z","shell.execute_reply.started":"2024-12-16T01:49:33.074742Z","shell.execute_reply":"2024-12-16T01:49:33.083506Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = segnet_model(input_size=(256, 256, 3), num_classes=8)\nmodel.compile(\n    optimizer=Adam(),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy', rand_index, jaccard_index, precision, recall]\n)\nmodel2 = segnet_model(input_size=(256, 256, 3), num_classes=8)\nmodel2.compile(\n    optimizer=SGD(),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy', rand_index, jaccard_index, precision, recall]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:49:35.420697Z","iopub.execute_input":"2024-12-16T01:49:35.421052Z","iopub.status.idle":"2024-12-16T01:49:35.837960Z","shell.execute_reply.started":"2024-12-16T01:49:35.421023Z","shell.execute_reply":"2024-12-16T01:49:35.837013Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def get_image_paths(directory, extensions=[\".jpg\", \".png\"]):\n    return [os.path.join(directory, filename) for filename in os.listdir(directory) if any(filename.endswith(ext) for ext in extensions)]\n\n# Paths for training and validation data\ntrain_image_paths = get_image_paths(r\"/kaggle/working/IP-25/train_data/Images\")\ntrain_mask_paths = get_image_paths(r\"/kaggle/working/IP-25/train_data/Labels\")\nval_image_paths = get_image_paths(r\"/kaggle/working/IP-25/val_data/Images\")\nval_mask_paths = get_image_paths(r\"/kaggle/working/IP-25/val_data/Labels\")\n\n# Load data\ntrain_images = load_images(train_image_paths)\ntrain_masks = load_masks(train_mask_paths)\nval_images = load_images(val_image_paths)\nval_masks = load_masks(val_mask_paths)\n\n# Train the model\nhistory = model.fit(\n    train_images,\n    train_masks,\n    validation_data=(val_images, val_masks),\n    epochs=80,\n    batch_size=16\n)\nhistory2 = model2.fit(\n    train_images,\n    train_masks,\n    validation_data=(val_images, val_masks),\n    epochs=80,\n    batch_size=16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:49:37.695126Z","iopub.execute_input":"2024-12-16T01:49:37.695463Z"}},"outputs":[],"execution_count":null}]}